{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac43684",
   "metadata": {},
   "source": [
    "# ü§ñ Support Vector Machines (SVM) ‚Äî Interactive Notebook\n",
    "### Python for Machine Learning | Middle School Edition\n",
    "\n",
    "---\n",
    "\n",
    "**In this notebook we will:**\n",
    "- üîµ Classify data into **2 groups** (Binary Classification)\n",
    "- üåà Classify data into **3+ groups** (Multi-Class Classification)\n",
    "- üéõÔ∏è See how changing the **C parameter** affects accuracy\n",
    "- üî≠ See how different **Kernels** change the decision boundary\n",
    "- üìä Build heatmaps to find the **best settings** for SVM\n",
    "\n",
    "> **Tip:** Run each cell from top to bottom using **Shift + Enter**. Watch the charts appear!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f24d1",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 0 ‚Äî Setup: Import Libraries\n",
    "\n",
    "First, let's import everything we need. Think of this as getting all your art supplies ready before you start a painting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd36e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Core libraries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ‚îÄ‚îÄ Scikit-learn tools ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import (make_moons, make_circles, make_blobs,\n",
    "                               make_classification, load_iris, load_wine)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                              confusion_matrix, ConfusionMatrixDisplay)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ‚îÄ‚îÄ Plot style ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#f8f9fa',\n",
    "    'axes.facecolor':   '#ffffff',\n",
    "    'axes.grid':        True,\n",
    "    'grid.alpha':       0.3,\n",
    "    'font.size':        11,\n",
    "})\n",
    "COLORS  = ['#e74c3c', '#3498db', '#27ae60', '#f39c12', '#9b59b6']\n",
    "CMAP_BG = plt.cm.RdYlGn\n",
    "\n",
    "print(\"‚úÖ Libraries loaded ‚Äî ready to go!\")\n",
    "print(f\"   NumPy {np.__version__} | Matplotlib {plt.matplotlib.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d2b8b9",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Helper Function ‚Äî Plot Decision Boundary\n",
    "\n",
    "This function draws the colored regions showing what SVM predicts in each zone. We will reuse it many times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a361bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(ax, clf, X, y, title='', show_sv=True,\n",
    "                           cmap=plt.cm.RdYlGn, alpha=0.25):\n",
    "    \"\"\"Plot the decision boundary and data points for a trained SVM.\"\"\"\n",
    "    h = 0.04\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=alpha, cmap=cmap)\n",
    "    ax.contour(xx, yy, Z, colors='#333333', linewidths=1.5, levels=np.unique(Z)[:-1] + 0.5)\n",
    "\n",
    "    n_classes = len(np.unique(y))\n",
    "    for i, cls in enumerate(np.unique(y)):\n",
    "        mask = y == cls\n",
    "        ax.scatter(X[mask, 0], X[mask, 1],\n",
    "                   s=70, color=COLORS[i % len(COLORS)],\n",
    "                   edgecolors='white', linewidths=0.5,\n",
    "                   zorder=5, label=f'Class {cls}')\n",
    "\n",
    "    # Highlight support vectors\n",
    "    if show_sv and hasattr(clf, 'support_vectors_'):\n",
    "        sv = clf.support_vectors_\n",
    "        ax.scatter(sv[:, 0], sv[:, 1], s=200, facecolors='none',\n",
    "                   edgecolors='gold', linewidths=2, zorder=6, label='Support Vectors')\n",
    "\n",
    "    acc = accuracy_score(y, clf.predict(X))\n",
    "    ax.set_title(f'{title}\\nAccuracy: {acc*100:.1f}%', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=8, loc='upper left')\n",
    "    return acc\n",
    "\n",
    "print(\"‚úÖ Helper function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef1646",
   "metadata": {},
   "source": [
    "---\n",
    "## üîµ Section 1 ‚Äî Binary Classification (2 Classes)\n",
    "\n",
    "Binary means **two categories** ‚Äî like yes/no, pass/fail, spam/not-spam.\n",
    "\n",
    "We will test SVM on **three toy datasets** that get progressively trickier:\n",
    "1. üç¶ **Linearly Separable** ‚Äî a straight line works perfectly\n",
    "2. üåô **Moons** ‚Äî two crescent-moon shapes interleaved\n",
    "3. ‚≠ï **Circles** ‚Äî one group surrounds the other in a ring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8977b4a",
   "metadata": {},
   "source": [
    "### 1a. Generate Three Toy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Dataset 1: Linearly separable blobs\n",
    "X_lin, y_lin = make_blobs(n_samples=200, centers=2,\n",
    "                           cluster_std=0.8, random_state=42)\n",
    "\n",
    "# Dataset 2: Two moons (curved, not linearly separable)\n",
    "X_moon, y_moon = make_moons(n_samples=200, noise=0.18, random_state=42)\n",
    "\n",
    "# Dataset 3: Concentric circles (ring inside ring)\n",
    "X_circ, y_circ = make_circles(n_samples=200, noise=0.12,\n",
    "                                factor=0.45, random_state=42)\n",
    "\n",
    "datasets = [\n",
    "    (X_lin,  y_lin,  'Toy 1: Blobs (easy)\\nUse: Linear Kernel'),\n",
    "    (X_moon, y_moon, 'Toy 2: Moons (medium)\\nUse: RBF Kernel'),\n",
    "    (X_circ, y_circ, 'Toy 3: Circles (hard)\\nUse: RBF Kernel'),\n",
    "]\n",
    "\n",
    "# Quick peek at sizes\n",
    "for name, (X, y, title) in enumerate(datasets):\n",
    "    print(f\"Dataset {name+1}: {X.shape[0]} samples, \"\n",
    "          f\"Class 0: {sum(y==0)}, Class 1: {sum(y==1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41621d4",
   "metadata": {},
   "source": [
    "### 1b. Visualise the Raw Data\n",
    "\n",
    "Let's look at the data **before** training any model. Can you guess which dataset is easiest to separate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "fig.suptitle('Binary Classification ‚Äî Three Toy Datasets (Raw Data)',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "for ax, (X, y, title) in zip(axes, datasets):\n",
    "    for cls in [0, 1]:\n",
    "        ax.scatter(X[y==cls, 0], X[y==cls, 1],\n",
    "                   s=60, color=COLORS[cls], alpha=0.8,\n",
    "                   edgecolors='white', linewidths=0.4,\n",
    "                   label=f'Class {cls}')\n",
    "    ax.set_title(title, fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Notice: Dataset 1 can be split by a straight line.\")\n",
    "print(\"Datasets 2 & 3 need curved boundaries ‚Äî a straight line would fail!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288ab3e",
   "metadata": {},
   "source": [
    "### 1c. Scale, Train, and Plot Decision Boundaries\n",
    "\n",
    "We pick the best kernel for each dataset and see the results. Remember ‚Äî always **scale** your data before SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'rbf']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "fig.suptitle('Binary SVM ‚Äî Decision Boundaries on Each Dataset',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "for ax, (X, y, title), kernel in zip(axes, datasets, kernels):\n",
    "    # Split & scale\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_sc = scaler.fit_transform(X_tr)\n",
    "    X_te_sc = scaler.transform(X_te)\n",
    "    X_sc    = scaler.transform(X)\n",
    "\n",
    "    # Train\n",
    "    clf = SVC(kernel=kernel, C=1.0, random_state=42)\n",
    "    clf.fit(X_tr_sc, y_tr)\n",
    "\n",
    "    # Plot\n",
    "    test_acc = accuracy_score(y_te, clf.predict(X_te_sc))\n",
    "    sv_count = len(clf.support_vectors_)\n",
    "    plot_decision_boundary(ax, clf, X_sc, y,\n",
    "                           title=f'{title}\\nKernel={kernel} | Test Acc={test_acc*100:.1f}%')\n",
    "    ax.set_xlabel(f'Support Vectors: {sv_count}', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Gold circles = Support Vectors (the 'VIP' points closest to the boundary)\")\n",
    "print(\"The shaded regions show which class SVM predicts in each zone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b773911",
   "metadata": {},
   "source": [
    "### 1d. Real-ish Example ‚Äî Will the Student Pass? üéì\n",
    "\n",
    "Let's use a dataset that feels more realistic: predicting if a student **passes or needs extra practice** based on their homework and quiz scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "n = 60\n",
    "\n",
    "# Students who passed (high scores)\n",
    "pass_hw   = np.random.normal(76, 9, n)\n",
    "pass_quiz = np.random.normal(73, 9, n)\n",
    "\n",
    "# Students who need practice (lower scores)\n",
    "fail_hw   = np.random.normal(46, 9, n)\n",
    "fail_quiz = np.random.normal(43, 9, n)\n",
    "\n",
    "X_stu = np.vstack([np.column_stack([pass_hw, pass_quiz]),\n",
    "                   np.column_stack([fail_hw,  fail_quiz])])\n",
    "y_stu = np.array([1]*n + [0]*n)   # 1=Pass, 0=Needs Practice\n",
    "\n",
    "# Split & scale\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_stu, y_stu,\n",
    "                                            test_size=0.2, random_state=42)\n",
    "scaler_stu = StandardScaler()\n",
    "X_tr_sc = scaler_stu.fit_transform(X_tr)\n",
    "X_te_sc = scaler_stu.transform(X_te)\n",
    "X_sc    = scaler_stu.transform(X_stu)\n",
    "\n",
    "# Train\n",
    "clf_stu = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "clf_stu.fit(X_tr_sc, y_tr)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plot_decision_boundary(ax, clf_stu, X_sc, y_stu,\n",
    "                       title='Will the Student Pass? (RBF Kernel, C=1.0)')\n",
    "ax.set_xlabel('Homework Score (scaled)', fontsize=11)\n",
    "ax.set_ylabel('Quiz Score (scaled)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict new students\n",
    "new_students = np.array([[80, 75],   # strong student\n",
    "                          [50, 55],   # struggling student\n",
    "                          [63, 60]])  # borderline student\n",
    "new_sc = scaler_stu.transform(new_students)\n",
    "preds  = clf_stu.predict(new_sc)\n",
    "labels = ['Pass', 'Needs Practice']\n",
    "\n",
    "print(\"\\n--- Predicting New Students ---\")\n",
    "for (hw, qz), p in zip(new_students, preds):\n",
    "    print(f\"  HW={hw}, Quiz={qz}  ‚Üí  {labels[p]}\")\n",
    "print(f\"\\nTest accuracy: {accuracy_score(y_te, clf_stu.predict(X_te_sc))*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609d9ee",
   "metadata": {},
   "source": [
    "---\n",
    "## üåà Section 2 ‚Äî Multi-Class Classification (3+ Classes)\n",
    "\n",
    "SVM was designed for **two** classes, but we can extend it to handle many classes using two strategies:\n",
    "\n",
    "| Strategy | How it works | sklearn |\n",
    "|----------|-------------|---------|\n",
    "| **One-vs-Rest (OvR)** | Train 1 classifier per class vs all others | `OneVsRestClassifier(SVC())` |\n",
    "| **One-vs-One (OvO)** | Train 1 classifier per *pair* of classes | `SVC()` ‚Üê **default!** |\n",
    "\n",
    "We'll test both on three datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d82825",
   "metadata": {},
   "source": [
    "### 2a. Three Multi-Class Toy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0abafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Dataset A: 3 clearly separated blobs\n",
    "X_3blob, y_3blob = make_blobs(n_samples=300, centers=3,\n",
    "                               cluster_std=0.9, random_state=42)\n",
    "\n",
    "# Dataset B: 4 blobs ‚Äî slightly overlapping\n",
    "X_4blob, y_4blob = make_blobs(n_samples=400, centers=4,\n",
    "                               cluster_std=1.3, random_state=10)\n",
    "\n",
    "# Dataset C: Iris flowers (real botanical dataset!)\n",
    "iris   = load_iris()\n",
    "X_iris = iris.data[:, [2, 3]]     # petal length & petal width (best 2 features)\n",
    "y_iris = iris.target\n",
    "iris_names = iris.target_names\n",
    "\n",
    "multi_datasets = [\n",
    "    (X_3blob, y_3blob, '3 Blobs (3 classes)',    None),\n",
    "    (X_4blob, y_4blob, '4 Blobs (4 classes)',    None),\n",
    "    (X_iris,  y_iris,  'Iris Flowers (3 species)', iris_names),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "fig.suptitle('Multi-Class Datasets ‚Äî Raw Data', fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "for ax, (X, y, title, names) in zip(axes, multi_datasets):\n",
    "    for i, cls in enumerate(np.unique(y)):\n",
    "        lbl = names[cls] if names is not None else f'Class {cls}'\n",
    "        ax.scatter(X[y==cls, 0], X[y==cls, 1],\n",
    "                   s=60, color=COLORS[i], alpha=0.8,\n",
    "                   edgecolors='white', linewidths=0.4, label=lbl)\n",
    "    ax.set_title(title, fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074d6fb",
   "metadata": {},
   "source": [
    "### 2b. OvR vs OvO ‚Äî Side-by-Side on Each Dataset\n",
    "\n",
    "We train **both strategies** on each dataset and compare. Do they give the same result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96123121",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "fig.suptitle('Multi-Class SVM: OvR (top row)  vs  OvO (bottom row)',\n",
    "             fontsize=14, fontweight='bold', y=1.01)\n",
    "\n",
    "strategy_labels = ['One-vs-Rest (OvR)', 'One-vs-One (OvO, SVC default)']\n",
    "\n",
    "for col, (X, y, ds_title, names) in enumerate(multi_datasets):\n",
    "    scaler_mc = StandardScaler()\n",
    "    X_sc = scaler_mc.fit_transform(X)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_sc, y,\n",
    "                                               test_size=0.25, random_state=42)\n",
    "\n",
    "    clfs = [\n",
    "        OneVsRestClassifier(SVC(kernel='rbf', C=2.0, random_state=42)),\n",
    "        SVC(kernel='rbf', C=2.0, decision_function_shape='ovo', random_state=42),\n",
    "    ]\n",
    "\n",
    "    for row, (clf, strat) in enumerate(zip(clfs, strategy_labels)):\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        ax = axes[row][col]\n",
    "        cmap = plt.cm.Pastel1 if len(np.unique(y)) > 2 else plt.cm.RdYlGn\n",
    "\n",
    "        # Plot regions\n",
    "        h = 0.04\n",
    "        x0min, x0max = X_sc[:,0].min()-0.5, X_sc[:,0].max()+0.5\n",
    "        x1min, x1max = X_sc[:,1].min()-0.5, X_sc[:,1].max()+0.5\n",
    "        xx, yy = np.meshgrid(np.arange(x0min, x0max, h),\n",
    "                              np.arange(x1min, x1max, h))\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, alpha=0.22, cmap=cmap)\n",
    "        ax.contour(xx, yy, Z, colors='#555', linewidths=1.2)\n",
    "\n",
    "        # Plot points\n",
    "        for i, cls in enumerate(np.unique(y)):\n",
    "            lbl = names[cls] if names is not None else f'Class {cls}'\n",
    "            ax.scatter(X_sc[y==cls, 0], X_sc[y==cls, 1],\n",
    "                       s=55, color=COLORS[i], alpha=0.85,\n",
    "                       edgecolors='white', linewidths=0.4, label=lbl)\n",
    "\n",
    "        test_acc = accuracy_score(y_te, clf.predict(X_te))\n",
    "        ax.set_title(f'{ds_title}\\n{strat} | Acc={test_acc*100:.1f}%',\n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.legend(fontsize=7, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Notice how OvR and OvO often produce very similar boundaries!\")\n",
    "print(\"The key difference shows up when classes are close together.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dea05",
   "metadata": {},
   "source": [
    "### 2c. Peek Inside OvR ‚Äî One Binary Classifier per Class\n",
    "\n",
    "Let's visualise **each individual binary classifier** that OvR trains. For 3 classes, there are 3 classifiers!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1054fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler3 = StandardScaler()\n",
    "X3_sc   = scaler3.fit_transform(X_3blob)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "fig.suptitle('Inside OvR ‚Äî Each Classifier Asks \"Is it THIS class, or the rest?\"',\n",
    "             fontsize=13, fontweight='bold', y=1.02)\n",
    "\n",
    "class_labels = ['Class 0 (Red)', 'Class 1 (Blue)', 'Class 2 (Green)']\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    # Binary labels: class i = 1, everything else = 0\n",
    "    y_bin = (y_3blob == i).astype(int)\n",
    "\n",
    "    clf_bin = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "    clf_bin.fit(X3_sc, y_bin)\n",
    "\n",
    "    # Regions\n",
    "    h = 0.05\n",
    "    xx, yy = np.meshgrid(np.arange(X3_sc[:,0].min()-0.5, X3_sc[:,0].max()+0.5, h),\n",
    "                         np.arange(X3_sc[:,1].min()-0.5, X3_sc[:,1].max()+0.5, h))\n",
    "    Z = clf_bin.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.20,\n",
    "                colors=[COLORS[i] if v==1 else '#eeeeee' for v in [0,1]])\n",
    "    ax.contour(xx, yy, Z, colors=[COLORS[i]], linewidths=2.5)\n",
    "\n",
    "    # Points: highlight the target class, grey out the rest\n",
    "    for j in range(3):\n",
    "        c     = COLORS[j] if j==i else '#cccccc'\n",
    "        alpha = 0.9 if j==i else 0.4\n",
    "        ax.scatter(X3_sc[y_3blob==j, 0], X3_sc[y_3blob==j, 1],\n",
    "                   s=60, color=c, alpha=alpha, edgecolors='white', linewidths=0.4)\n",
    "\n",
    "    acc = accuracy_score(y_bin, clf_bin.predict(X3_sc))\n",
    "    ax.set_title(f'Classifier {i+1}: {class_labels[i]} vs Rest\\nAcc={acc*100:.1f}%',\n",
    "                 fontsize=11, fontweight='bold', color=COLORS[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d30f54",
   "metadata": {},
   "source": [
    "### 2d. Confusion Matrix ‚Äî Iris Multi-Class\n",
    "\n",
    "A confusion matrix tells us **exactly** which flowers the model got right, and which ones it mixed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae264cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Iris dataset (all 4 features for best accuracy)\n",
    "X_iris_full = iris.data\n",
    "y_iris_full = iris.target\n",
    "\n",
    "scaler_iris = StandardScaler()\n",
    "X_sc_iris   = scaler_iris.fit_transform(X_iris_full)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_sc_iris, y_iris_full,\n",
    "                                            test_size=0.25, random_state=42)\n",
    "\n",
    "# Train OvO (SVC default)\n",
    "clf_iris = SVC(kernel='rbf', C=2.0, random_state=42)\n",
    "clf_iris.fit(X_tr, y_tr)\n",
    "y_pred = clf_iris.predict(X_te)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle('Iris Flower Classification ‚Äî Results', fontsize=13, fontweight='bold')\n",
    "\n",
    "cm   = confusion_matrix(y_te, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=iris.target_names)\n",
    "disp.plot(ax=axes[0], colorbar=False, cmap='Blues')\n",
    "axes[0].set_title('Confusion Matrix\\n(diagonal = correct predictions)', fontweight='bold')\n",
    "\n",
    "# Per-class bar chart\n",
    "report = classification_report(y_te, y_pred, target_names=iris.target_names, output_dict=True)\n",
    "species  = iris.target_names\n",
    "f1_scores = [report[s]['f1-score'] for s in species]\n",
    "bars = axes[1].bar(species, f1_scores, color=COLORS[:3], edgecolor='white', width=0.5)\n",
    "axes[1].set_ylim(0, 1.15)\n",
    "axes[1].set_ylabel('F1 Score', fontsize=11)\n",
    "axes[1].set_title('F1 Score per Flower Species\\n(1.0 = perfect)', fontweight='bold')\n",
    "for bar, score in zip(bars, f1_scores):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                 f'{score:.2f}', ha='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOverall Test Accuracy: {accuracy_score(y_te, y_pred)*100:.1f}%\")\n",
    "print(\"\\nFull Report:\")\n",
    "print(classification_report(y_te, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07acee42",
   "metadata": {},
   "source": [
    "### 2e. Bonus Dataset ‚Äî Wine Classification üç∑\n",
    "\n",
    "The Wine dataset has **13 features** and **3 classes** (three wine varieties). More features = harder to visualise but often more accurate!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine   = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "print(\"Wine Dataset Info:\")\n",
    "print(f\"  Samples: {X_wine.shape[0]}, Features: {X_wine.shape[1]}\")\n",
    "print(f\"  Classes: {list(wine.target_names)}\")\n",
    "print(f\"  Per class: {[sum(y_wine==i) for i in range(3)]}\")\n",
    "\n",
    "# Scale & split\n",
    "scaler_wine = StandardScaler()\n",
    "X_sc_wine   = scaler_wine.fit_transform(X_wine)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_sc_wine, y_wine,\n",
    "                                            test_size=0.25, random_state=42)\n",
    "\n",
    "# Compare strategies\n",
    "for strat_name, clf in [\n",
    "    ('OvO (SVC default)',  SVC(kernel='rbf', C=5.0, random_state=42)),\n",
    "    ('OvR',                OneVsRestClassifier(SVC(kernel='rbf', C=5.0, random_state=42))),\n",
    "]:\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    acc = accuracy_score(y_te, clf.predict(X_te))\n",
    "    cv  = cross_val_score(clf, X_sc_wine, y_wine, cv=5).mean()\n",
    "    print(f\"  {strat_name:<22} Test Acc={acc*100:.1f}%   5-fold CV={cv*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36a56f",
   "metadata": {},
   "source": [
    "---\n",
    "## üéõÔ∏è Section 3 ‚Äî The C Parameter: Strict vs Flexible\n",
    "\n",
    "The **C parameter** controls how much SVM cares about misclassifying training points:\n",
    "\n",
    "| C value | Behaviour | Risk |\n",
    "|---------|-----------|------|\n",
    "| **Very small** (0.001) | Very flexible, big margin, allows mistakes | Might underfit |\n",
    "| **Medium** (1.0) | Balanced ‚Äî usually the best starting point | ‚Äî |\n",
    "| **Very large** (1000) | Very strict, no mistakes allowed, small margin | Might overfit |\n",
    "\n",
    "> **Analogy:** C is like a teacher's strictness on a test. Too strict = memorises answers, fails on new questions. Too flexible = doesn't learn enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f3943",
   "metadata": {},
   "source": [
    "### 3a. Visualise C on the Moons Dataset\n",
    "\n",
    "Watch how the boundary changes as C goes from tiny to huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mc, y_mc = make_moons(n_samples=250, noise=0.22, random_state=42)\n",
    "X_tr_c, X_te_c, y_tr_c, y_te_c = train_test_split(X_mc, y_mc, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler_c = StandardScaler()\n",
    "X_tr_cs  = scaler_c.fit_transform(X_tr_c)\n",
    "X_te_cs  = scaler_c.transform(X_te_c)\n",
    "X_cs     = scaler_c.transform(X_mc)\n",
    "\n",
    "C_values = [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "fig.suptitle('Effect of C Parameter on Decision Boundary (RBF Kernel, Moons Dataset)',\n",
    "             fontsize=14, fontweight='bold', y=1.01)\n",
    "\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "for ax, C in zip(axes.flatten(), C_values):\n",
    "    clf_c = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "    clf_c.fit(X_tr_cs, y_tr_c)\n",
    "\n",
    "    tr_acc = accuracy_score(y_tr_c, clf_c.predict(X_tr_cs))\n",
    "    te_acc = accuracy_score(y_te_c, clf_c.predict(X_te_cs))\n",
    "    train_accs.append(tr_acc)\n",
    "    test_accs.append(te_acc)\n",
    "\n",
    "    h = 0.04\n",
    "    xx, yy = np.meshgrid(np.arange(X_cs[:,0].min()-0.4, X_cs[:,0].max()+0.4, h),\n",
    "                         np.arange(X_cs[:,1].min()-0.4, X_cs[:,1].max()+0.4, h))\n",
    "    Z = clf_c.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.25, cmap=CMAP_BG)\n",
    "    ax.contour(xx, yy, Z, colors='#333', linewidths=1.5)\n",
    "\n",
    "    for cls in [0, 1]:\n",
    "        ax.scatter(X_cs[y_mc==cls, 0], X_cs[y_mc==cls, 1],\n",
    "                   s=55, color=COLORS[cls], alpha=0.8,\n",
    "                   edgecolors='white', linewidths=0.4)\n",
    "\n",
    "    sv_n = len(clf_c.support_vectors_)\n",
    "    color = '#c0392b' if (tr_acc - te_acc > 0.06) else '#27ae60'\n",
    "    ax.set_title(f'C = {C}\\nTrain: {tr_acc*100:.1f}%  Test: {te_acc*100:.1f}%  SVs: {sv_n}',\n",
    "                 fontsize=10.5, fontweight='bold', color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Red title = overfitting warning (train >> test)\")\n",
    "print(\"Green title = healthy gap between train and test accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3553a26",
   "metadata": {},
   "source": [
    "### 3b. Train vs Test Accuracy Curve\n",
    "\n",
    "This plot shows the classic **overfitting curve** ‚Äî as C grows, training accuracy rises but test accuracy eventually falls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range   = np.logspace(-3, 4, 40)\n",
    "tr_scores = []\n",
    "te_scores = []\n",
    "\n",
    "for C in C_range:\n",
    "    clf_tmp = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "    clf_tmp.fit(X_tr_cs, y_tr_c)\n",
    "    tr_scores.append(accuracy_score(y_tr_c, clf_tmp.predict(X_tr_cs)))\n",
    "    te_scores.append(accuracy_score(y_te_c, clf_tmp.predict(X_te_cs)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.semilogx(C_range, tr_scores, 'o-', color='#e74c3c', lw=2, ms=4, label='Training Accuracy')\n",
    "ax.semilogx(C_range, te_scores, 's-', color='#3498db', lw=2, ms=4, label='Test Accuracy')\n",
    "\n",
    "# Shade the overfit region\n",
    "best_c_idx = np.argmax(te_scores)\n",
    "best_c     = C_range[best_c_idx]\n",
    "ax.axvline(best_c, color='#27ae60', linestyle='--', lw=2, label=f'Best C ‚âà {best_c:.2f}')\n",
    "ax.fill_between(C_range, tr_scores, te_scores, alpha=0.10, color='red',\n",
    "                label='Overfitting gap')\n",
    "\n",
    "ax.set_xlabel('C value (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Train vs Test Accuracy as C Changes\\n'\n",
    "             '(left = too flexible / right = too strict)', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda v, _: f'{v*100:.0f}%'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Best C for this dataset: {best_c:.3f}\")\n",
    "print(f\"Best test accuracy:      {max(te_scores)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53a163",
   "metadata": {},
   "source": [
    "### 3c. Number of Support Vectors vs C\n",
    "\n",
    "As C increases, SVM gets stricter and uses **fewer** support vectors. Let's see this relationship!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ecfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_test = [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n",
    "sv_counts = []\n",
    "\n",
    "for C in C_test:\n",
    "    clf_sv = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "    clf_sv.fit(X_tr_cs, y_tr_c)\n",
    "    sv_counts.append(len(clf_sv.support_vectors_))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "axes[0].semilogx(C_test, sv_counts, 'D-', color='#9b59b6', lw=2, ms=8)\n",
    "axes[0].fill_between(C_test, sv_counts, alpha=0.15, color='#9b59b6')\n",
    "axes[0].set_xlabel('C value (log scale)', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Support Vectors', fontsize=12)\n",
    "axes[0].set_title('As C increases ‚Üí Fewer Support Vectors\\n(SVM becomes more selective)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Bar chart version\n",
    "bars = axes[1].bar([str(c) for c in C_test], sv_counts,\n",
    "                    color='#9b59b6', alpha=0.75, edgecolor='white')\n",
    "axes[1].set_xlabel('C value', fontsize=12)\n",
    "axes[1].set_ylabel('Support Vectors', fontsize=12)\n",
    "axes[1].set_title('Support Vector Count per C Value', fontsize=12, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "for bar, cnt in zip(bars, sv_counts):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 str(cnt), ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Small C  ‚Üí many support vectors ‚Üí loose boundary\")\n",
    "print(\"Large C  ‚Üí few support vectors  ‚Üí tight boundary (risk of overfitting)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181affc2",
   "metadata": {},
   "source": [
    "---\n",
    "## üî≠ Section 4 ‚Äî Kernel Comparison\n",
    "\n",
    "The **kernel** is the \"lens\" SVM uses to look at the data. Different kernels draw differently shaped boundaries:\n",
    "\n",
    "| Kernel | Shape of boundary | Best for |\n",
    "|--------|------------------|----------|\n",
    "| `linear` | Straight line | Linearly separable data |\n",
    "| `poly` | Curved, polynomial shape | Moderate complexity |\n",
    "| `rbf` | Circular / blob shapes | Most real-world data |\n",
    "| `sigmoid` | S-shaped curve | Rarely used |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a865e25",
   "metadata": {},
   "source": [
    "### 4a. All Four Kernels on Three Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_all = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "test_dsets  = [\n",
    "    (X_lin,  y_lin,  'Blobs (easy)'),\n",
    "    (X_moon, y_moon, 'Moons (medium)'),\n",
    "    (X_circ, y_circ, 'Circles (hard)'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(len(test_dsets), len(kernels_all),\n",
    "                         figsize=(17, 12))\n",
    "fig.suptitle('Kernel Comparison ‚Äî All Four Kernels on Three Datasets',\n",
    "             fontsize=15, fontweight='bold', y=1.01)\n",
    "\n",
    "for row, (X, y, ds_name) in enumerate(test_dsets):\n",
    "    scaler_k = StandardScaler()\n",
    "    X_sc_k   = scaler_k.fit_transform(X)\n",
    "    X_tr_k, X_te_k, y_tr_k, y_te_k = train_test_split(\n",
    "        X_sc_k, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    for col, kernel in enumerate(kernels_all):\n",
    "        ax = axes[row][col]\n",
    "        clf_k = SVC(kernel=kernel, C=1.0, degree=3, random_state=42)\n",
    "        clf_k.fit(X_tr_k, y_tr_k)\n",
    "        te_acc = accuracy_score(y_te_k, clf_k.predict(X_te_k))\n",
    "\n",
    "        h = 0.05\n",
    "        xx, yy = np.meshgrid(\n",
    "            np.arange(X_sc_k[:,0].min()-0.4, X_sc_k[:,0].max()+0.4, h),\n",
    "            np.arange(X_sc_k[:,1].min()-0.4, X_sc_k[:,1].max()+0.4, h))\n",
    "        Z = clf_k.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, alpha=0.25, cmap=CMAP_BG)\n",
    "        ax.contour(xx, yy, Z, colors='#444', linewidths=1.2)\n",
    "        for cls in np.unique(y):\n",
    "            ax.scatter(X_sc_k[y==cls, 0], X_sc_k[y==cls, 1],\n",
    "                       s=40, color=COLORS[cls], alpha=0.75,\n",
    "                       edgecolors='white', linewidths=0.3)\n",
    "\n",
    "        emoji = '‚úÖ' if te_acc > 0.88 else ('‚ö†Ô∏è' if te_acc > 0.75 else '‚ùå')\n",
    "        ax.set_title(f'{emoji} {kernel} | {te_acc*100:.1f}%',\n",
    "                     fontsize=10.5, fontweight='bold')\n",
    "\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(ds_name, fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚úÖ = Great (>88%)   ‚ö†Ô∏è = OK (75-88%)   ‚ùå = Poor (<75%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa064e0",
   "metadata": {},
   "source": [
    "### 4b. Kernel Accuracy Bar Chart ‚Äî Head-to-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6266e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}  # {dataset_name: {kernel: test_acc}}\n",
    "\n",
    "for X, y, ds_name in test_dsets:\n",
    "    scaler_bar = StandardScaler()\n",
    "    X_sc_bar   = scaler_bar.fit_transform(X)\n",
    "    X_tr_b, X_te_b, y_tr_b, y_te_b = train_test_split(\n",
    "        X_sc_bar, y, test_size=0.25, random_state=42)\n",
    "    results[ds_name] = {}\n",
    "    for kernel in kernels_all:\n",
    "        clf_b = SVC(kernel=kernel, C=1.0, degree=3, random_state=42)\n",
    "        clf_b.fit(X_tr_b, y_tr_b)\n",
    "        results[ds_name][kernel] = accuracy_score(y_te_b, clf_b.predict(X_te_b))\n",
    "\n",
    "# Plot grouped bar chart\n",
    "x     = np.arange(len(kernels_all))\n",
    "width = 0.25\n",
    "ds_colors = ['#3498db', '#e74c3c', '#27ae60']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "for i, (ds_name, kern_acc) in enumerate(results.items()):\n",
    "    vals = [kern_acc[k] for k in kernels_all]\n",
    "    bars = ax.bar(x + i*width, [v*100 for v in vals],\n",
    "                  width, label=ds_name, color=ds_colors[i],\n",
    "                  alpha=0.82, edgecolor='white')\n",
    "    for bar, v in zip(bars, vals):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2,\n",
    "                bar.get_height() + 0.5,\n",
    "                f'{v*100:.0f}%', ha='center', fontsize=8.5, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels([f'{k}' for k in kernels_all], fontsize=12)\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax.set_ylim(40, 110)\n",
    "ax.set_title('Kernel Accuracy Comparison ‚Äî Three Binary Datasets (C=1.0)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.axhline(90, color='grey', linestyle=':', alpha=0.5, label='90% reference')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6c0e5",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Section 5 ‚Äî C √ó Kernel Heatmaps: Finding the Sweet Spot\n",
    "\n",
    "Now let's combine everything: we'll try **every combination of C and kernel** and record the accuracy.\n",
    "This is called a **grid search** ‚Äî we build a table (heatmap) of results to find the best settings!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bc89d",
   "metadata": {},
   "source": [
    "### 5a. Heatmap ‚Äî Moons Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "C_grid       = [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500]\n",
    "kernel_grid  = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "scaler_hm = StandardScaler()\n",
    "X_hm = scaler_hm.fit_transform(X_moon)\n",
    "\n",
    "# Build accuracy matrix using 5-fold cross-validation\n",
    "hm_scores = np.zeros((len(kernel_grid), len(C_grid)))\n",
    "\n",
    "for ki, kernel in enumerate(kernel_grid):\n",
    "    for ci, C in enumerate(C_grid):\n",
    "        clf_hm = SVC(kernel=kernel, C=C, gamma='scale', degree=3, random_state=42)\n",
    "        scores = cross_val_score(clf_hm, X_hm, y_moon, cv=5, scoring='accuracy')\n",
    "        hm_scores[ki, ci] = scores.mean()\n",
    "    print(f\"  Done kernel='{kernel}'\")\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "im = ax.imshow(hm_scores, cmap='RdYlGn', aspect='auto',\n",
    "               vmin=hm_scores.min(), vmax=1.0)\n",
    "plt.colorbar(im, ax=ax, label='5-Fold CV Accuracy')\n",
    "\n",
    "ax.set_xticks(range(len(C_grid)))\n",
    "ax.set_xticklabels([str(c) for c in C_grid], fontsize=10)\n",
    "ax.set_yticks(range(len(kernel_grid)))\n",
    "ax.set_yticklabels(kernel_grid, fontsize=11, fontweight='bold')\n",
    "ax.set_xlabel('C value', fontsize=12)\n",
    "ax.set_title('Accuracy Heatmap: C √ó Kernel (Moons Dataset)\\n'\n",
    "             'Green = high accuracy  |  Red = low accuracy',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "# Annotate cells\n",
    "for ki in range(len(kernel_grid)):\n",
    "    for ci in range(len(C_grid)):\n",
    "        v = hm_scores[ki, ci]\n",
    "        txt_color = 'black' if v > 0.75 else 'white'\n",
    "        ax.text(ci, ki, f'{v*100:.0f}%', ha='center', va='center',\n",
    "                fontsize=9, fontweight='bold', color=txt_color)\n",
    "\n",
    "# Star the best cell\n",
    "best_ki, best_ci = np.unravel_index(hm_scores.argmax(), hm_scores.shape)\n",
    "ax.add_patch(plt.Rectangle((best_ci-0.5, best_ki-0.5), 1, 1,\n",
    "                             fill=False, edgecolor='gold', lw=3))\n",
    "ax.text(best_ci, best_ki - 0.62, '‚òÖ BEST', ha='center', fontsize=9,\n",
    "        color='gold', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest combination: kernel='{kernel_grid[best_ki]}', C={C_grid[best_ci]}\")\n",
    "print(f\"Best CV accuracy: {hm_scores[best_ki, best_ci]*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12641dbb",
   "metadata": {},
   "source": [
    "### 5b. Heatmap ‚Äî Iris Multi-Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65058a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_iris_hm = StandardScaler()\n",
    "X_iris_hm = scaler_iris_hm.fit_transform(iris.data)\n",
    "\n",
    "hm_iris = np.zeros((len(kernel_grid), len(C_grid)))\n",
    "\n",
    "for ki, kernel in enumerate(kernel_grid):\n",
    "    for ci, C in enumerate(C_grid):\n",
    "        clf_tmp = SVC(kernel=kernel, C=C, gamma='scale', degree=3, random_state=42)\n",
    "        scores  = cross_val_score(clf_tmp, X_iris_hm, iris.target, cv=5)\n",
    "        hm_iris[ki, ci] = scores.mean()\n",
    "    print(f\"  Done kernel='{kernel}'\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "im = ax.imshow(hm_iris, cmap='RdYlGn', aspect='auto',\n",
    "               vmin=hm_iris.min(), vmax=1.0)\n",
    "plt.colorbar(im, ax=ax, label='5-Fold CV Accuracy')\n",
    "\n",
    "ax.set_xticks(range(len(C_grid)))\n",
    "ax.set_xticklabels([str(c) for c in C_grid], fontsize=10)\n",
    "ax.set_yticks(range(len(kernel_grid)))\n",
    "ax.set_yticklabels(kernel_grid, fontsize=11, fontweight='bold')\n",
    "ax.set_xlabel('C value', fontsize=12)\n",
    "ax.set_title('Accuracy Heatmap: C √ó Kernel (Iris Multi-Class Dataset)\\n'\n",
    "             'Green = high accuracy  |  Red = low accuracy',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "for ki in range(len(kernel_grid)):\n",
    "    for ci in range(len(C_grid)):\n",
    "        v = hm_iris[ki, ci]\n",
    "        txt_color = 'black' if v > 0.80 else 'white'\n",
    "        ax.text(ci, ki, f'{v*100:.0f}%', ha='center', va='center',\n",
    "                fontsize=9, fontweight='bold', color=txt_color)\n",
    "\n",
    "best_ki_i, best_ci_i = np.unravel_index(hm_iris.argmax(), hm_iris.shape)\n",
    "ax.add_patch(plt.Rectangle((best_ci_i-0.5, best_ki_i-0.5), 1, 1,\n",
    "                             fill=False, edgecolor='gold', lw=3))\n",
    "ax.text(best_ci_i, best_ki_i - 0.62, '‚òÖ BEST', ha='center', fontsize=9,\n",
    "        color='gold', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest combination: kernel='{kernel_grid[best_ki_i]}', C={C_grid[best_ci_i]}\")\n",
    "print(f\"Best CV accuracy: {hm_iris[best_ki_i, best_ci_i]*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155f082",
   "metadata": {},
   "source": [
    "### 5c. Side-by-Side Heatmap Comparison ‚Äî All Three Binary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_short = [0.01, 0.1, 1, 10, 100]\n",
    "kern_short = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "fig.suptitle('C √ó Kernel Accuracy Heatmap ‚Äî Three Datasets Compared',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "for ax, (X, y, ds_name) in zip(axes, test_dsets):\n",
    "    sc = StandardScaler()\n",
    "    Xs = sc.fit_transform(X)\n",
    "    mat = np.zeros((len(kern_short), len(C_short)))\n",
    "    for ki, k in enumerate(kern_short):\n",
    "        for ci, C in enumerate(C_short):\n",
    "            clf_s = SVC(kernel=k, C=C, gamma='scale', degree=3, random_state=42)\n",
    "            mat[ki, ci] = cross_val_score(clf_s, Xs, y, cv=5).mean()\n",
    "\n",
    "    im = ax.imshow(mat, cmap='RdYlGn', aspect='auto',\n",
    "                   vmin=mat.min(), vmax=1.0)\n",
    "    ax.set_xticks(range(len(C_short)))\n",
    "    ax.set_xticklabels(C_short, fontsize=10)\n",
    "    ax.set_yticks(range(len(kern_short)))\n",
    "    ax.set_yticklabels(kern_short, fontsize=10)\n",
    "    ax.set_xlabel('C')\n",
    "    ax.set_title(ds_name, fontsize=12, fontweight='bold')\n",
    "    for ki in range(len(kern_short)):\n",
    "        for ci in range(len(C_short)):\n",
    "            v = mat[ki, ci]\n",
    "            ax.text(ci, ki, f'{v*100:.0f}', ha='center', va='center',\n",
    "                    fontsize=10, fontweight='bold',\n",
    "                    color='black' if v > 0.75 else 'white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Each number = cross-validated accuracy % for that C + kernel combo.\")\n",
    "print(\"Compare columns to see which C is best per dataset.\")\n",
    "print(\"Compare rows to see which kernel is best per dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05595ef1",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ Section 6 ‚Äî Let sklearn Find the Best Settings Automatically\n",
    "\n",
    "Instead of manually trying every combination, sklearn has `GridSearchCV` that does it for you ‚Äî automatically!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the search space\n",
    "param_grid = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__C':      [0.1, 1, 10, 100],\n",
    "    'svc__gamma':  ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Build a pipeline (scale + SVM)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc',    SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5,\n",
    "                            scoring='accuracy', n_jobs=-1, verbose=0)\n",
    "\n",
    "print(\"Searching best params on Moons dataset...\")\n",
    "grid_search.fit(X_moon, y_moon)\n",
    "\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_*100:.1f}%\")\n",
    "\n",
    "# Show top 5 results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top5 = results_df.sort_values('mean_test_score', ascending=False)[\n",
    "    ['param_svc__kernel', 'param_svc__C', 'param_svc__gamma', 'mean_test_score']\n",
    "].head(5)\n",
    "top5.columns = ['Kernel', 'C', 'Gamma', 'CV Accuracy']\n",
    "top5['CV Accuracy'] = (top5['CV Accuracy'] * 100).round(1).astype(str) + '%'\n",
    "print(\"\\nTop 5 Combinations:\")\n",
    "print(top5.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same grid search on Iris\n",
    "print(\"Searching best params on Iris dataset (all 4 features)...\")\n",
    "grid_iris = GridSearchCV(pipeline, param_grid, cv=5,\n",
    "                          scoring='accuracy', n_jobs=-1)\n",
    "grid_iris.fit(iris.data, iris.target)\n",
    "\n",
    "print(f\"\\nBest parameters for Iris: {grid_iris.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy: {grid_iris.best_score_*100:.1f}%\")\n",
    "\n",
    "# Plot parameter importance\n",
    "res_iris = pd.DataFrame(grid_iris.cv_results_)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle('GridSearchCV Results ‚Äî Iris Dataset', fontsize=13, fontweight='bold')\n",
    "\n",
    "# By kernel\n",
    "for kernel in ['linear', 'rbf', 'poly']:\n",
    "    subset = res_iris[res_iris['param_svc__kernel'] == kernel]\n",
    "    axes[0].plot(subset['param_svc__C'].astype(float),\n",
    "                 subset['mean_test_score'] * 100,\n",
    "                 'o-', label=kernel, linewidth=2, markersize=6)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('C value', fontsize=11)\n",
    "axes[0].set_ylabel('CV Accuracy (%)', fontsize=11)\n",
    "axes[0].set_title('Accuracy by Kernel & C Value', fontsize=11, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Bar: best accuracy per kernel\n",
    "best_by_kernel = res_iris.groupby('param_svc__kernel')['mean_test_score'].max() * 100\n",
    "axes[1].bar(best_by_kernel.index, best_by_kernel.values,\n",
    "            color=['#e74c3c','#3498db','#27ae60'], alpha=0.8, edgecolor='white')\n",
    "axes[1].set_ylabel('Best CV Accuracy (%)', fontsize=11)\n",
    "axes[1].set_title('Best Accuracy per Kernel (Iris)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylim(90, 102)\n",
    "for i, (kern, val) in enumerate(best_by_kernel.items()):\n",
    "    axes[1].text(i, val + 0.2, f'{val:.1f}%', ha='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b812666",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Section 7 ‚Äî Summary & Key Takeaways\n",
    "\n",
    "Congratulations ‚Äî you've completed the SVM notebook! Let's review what we learned:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Topic': [\n",
    "        'Binary SVM',\n",
    "        'Multi-Class (OvR)',\n",
    "        'Multi-Class (OvO)',\n",
    "        'Kernel: linear',\n",
    "        'Kernel: rbf',\n",
    "        'Kernel: poly',\n",
    "        'Small C',\n",
    "        'Large C',\n",
    "        'Best C finder',\n",
    "        'Scaling',\n",
    "    ],\n",
    "    'Key Point': [\n",
    "        'SVM draws the widest-margin boundary between 2 classes',\n",
    "        'N classifiers trained (1 per class vs rest); pick highest confidence',\n",
    "        'N*(N-1)/2 classifiers; majority vote decides; SVC() default',\n",
    "        'Straight line ‚Äî fast, good for linearly separable data',\n",
    "        'Circular/blob boundary ‚Äî best for most real-world data',\n",
    "        'Polynomial curve ‚Äî good for medium-complexity patterns',\n",
    "        'Flexible, wide margin, allows some errors, less overfitting',\n",
    "        'Strict, narrow margin, fits training data tightly, risk of overfitting',\n",
    "        'Use GridSearchCV to automatically search the best C & kernel',\n",
    "        'ALWAYS use StandardScaler before fitting SVM!',\n",
    "    ],\n",
    "    'Code Snippet': [\n",
    "        \"SVC(kernel='rbf', C=1.0)\",\n",
    "        \"OneVsRestClassifier(SVC())\",\n",
    "        \"SVC()  # OvO is the default\",\n",
    "        \"SVC(kernel='linear')\",\n",
    "        \"SVC(kernel='rbf')  # recommended default\",\n",
    "        \"SVC(kernel='poly', degree=3)\",\n",
    "        \"SVC(C=0.1)\",\n",
    "        \"SVC(C=100)\",\n",
    "        \"GridSearchCV(Pipeline([...]), param_grid, cv=5)\",\n",
    "        \"StandardScaler().fit_transform(X)\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(df_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16f641",
   "metadata": {},
   "source": [
    "### üéØ Practice Challenges\n",
    "\n",
    "Try these challenges to test your skills:\n",
    "\n",
    "1. **Beginner:** Create a new dataset using `make_blobs(centers=5)` and train an OvO SVM on it. What accuracy do you get?\n",
    "\n",
    "2. **Intermediate:** On the Circles dataset, find the single best (kernel, C) pair manually by trying different values. Beat 97% accuracy!\n",
    "\n",
    "3. **Advanced:** Load the Wine dataset (`load_wine()`), run GridSearchCV with all three kernels and C values from 0.01 to 1000, and visualise the results in a heatmap.\n",
    "\n",
    "4. **Explorer:** What happens when you change the `gamma` parameter in the RBF kernel? Try `gamma` values of 0.001, 0.1, 1, 10 on the Circles dataset and plot the boundaries.\n",
    "\n",
    "---\n",
    "*Great work! Every line of code you write brings you closer to being a machine learning pro!* üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

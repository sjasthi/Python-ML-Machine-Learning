{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Classifier\n",
        "### Siva.Jasthi@metrostate.edu\n",
        "Machine Learning and Data Mining"
      ],
      "metadata": {
        "id": "wQkmP8eROiXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Classifier using basic python"
      ],
      "metadata": {
        "id": "aP1VYtBSsdQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN using Basic python\n",
        "def euclidean_distance(x1, x2):\n",
        "    distance = 0\n",
        "    for i in range(len(x1)):\n",
        "        distance += (x1[i] - x2[i])**2\n",
        "    return distance ** 0.5\n",
        "\n",
        "\n",
        "\n",
        "def knn(data, query, k):\n",
        "    distances = []\n",
        "    for i in range(len(data)):\n",
        "        dist = euclidean_distance(data[i][:2], query)\n",
        "        distances.append((dist, data[i][2]))\n",
        "\n",
        "    # Sort the distances in ascending order\n",
        "    distances.sort()\n",
        "\n",
        "    # identify the nearest K neighbors\n",
        "    neighbors = []\n",
        "    for i in range(len(distances)):\n",
        "        if i >= k:\n",
        "            break\n",
        "        neighbors.append(distances[i][1])\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "\n",
        "def majority_vote(labels):\n",
        "    label_counts = {}\n",
        "    for label in labels:\n",
        "        if label in label_counts:\n",
        "            label_counts[label] += 1\n",
        "        else:\n",
        "            label_counts[label] = 1\n",
        "    sorted_counts = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_counts[0][0]\n",
        "\n",
        "\n",
        "def best_k(data, query, k_values):\n",
        "    best_accuracy = 0\n",
        "    best_k = None\n",
        "    for k in k_values:\n",
        "        neighbors = knn(data, query, k)\n",
        "        label = majority_vote(neighbors)\n",
        "        accuracy = neighbors.count(label) / len(neighbors)\n",
        "        print(k, \" = \", accuracy)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_k = k\n",
        "\n",
        "\n",
        "    return best_k, best_accuracy\n",
        "\n",
        "\n",
        "# Test the classifier\n",
        "data = [[2, 3, 'A'], [4, 2, 'B'], [1, 5, 'A'], [4, 4, 'B']]\n",
        "data = [[2, 3, 'A'], [4, 2, 'B'], [1, 5, 'A'], [4, 4, 'B'], [6, 8, 'A'], [9, 1, 'B'], [3, 7, 'A'], [5, 6, 'B'], [2, 9, 'A'], [7, 3, 'B'], [8, 5, 'A'], [3, 2, 'B'], [1, 7, 'A'], [5, 4, 'B'], [6, 2, 'A'], [8, 7, 'B'], [2, 6, 'A'], [7, 1, 'B'], [3, 5, 'A'], [9, 3, 'B'], [4, 7, 'A']]\n",
        "\n",
        "\n",
        "# we want to classify [3,4]\n",
        "query = [2, 9]\n",
        "\n",
        "# Try out different k values and identify the best K\n",
        "k_values = [3, 5, 7, 9, 11, 13, 15]\n",
        "best_k, best_accuracy = best_k(data, query, k_values)\n",
        "print('best k:', best_k)\n",
        "print('best accuracy:', best_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "# Rebuild the classifier with the best K\n",
        "neighbors = knn(data, query, best_k)\n",
        "label = majority_vote(neighbors)\n",
        "print('prediction for', query, '=', label)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDYLLoVnsg-C",
        "outputId": "d538aed5-39b3-4436-ea0c-1fd6a8d79226"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 1: Basic KNN - Data Points and Query Point"
      ],
      "metadata": {
        "id": "viz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract coordinates and labels\n",
        "class_A = [point for point in data if point[2] == 'A']\n",
        "class_B = [point for point in data if point[2] == 'B']\n",
        "\n",
        "# Separate x and y coordinates\n",
        "A_x = [point[0] for point in class_A]\n",
        "A_y = [point[1] for point in class_A]\n",
        "B_x = [point[0] for point in class_B]\n",
        "B_y = [point[1] for point in class_B]\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(A_x, A_y, c='blue', s=100, alpha=0.6, edgecolors='black', label='Class A', marker='o')\n",
        "plt.scatter(B_x, B_y, c='red', s=100, alpha=0.6, edgecolors='black', label='Class B', marker='s')\n",
        "\n",
        "# Plot query point\n",
        "plt.scatter(query[0], query[1], c='green', s=300, alpha=0.8, edgecolors='black', \n",
        "            marker='*', label=f'Query Point {query}', linewidths=2)\n",
        "\n",
        "# Find the k=3 nearest neighbors and draw circles\n",
        "distances_viz = []\n",
        "for point in data:\n",
        "    dist = euclidean_distance(point[:2], query)\n",
        "    distances_viz.append((dist, point))\n",
        "distances_viz.sort()\n",
        "\n",
        "# Highlight the 3 nearest neighbors\n",
        "for i in range(3):\n",
        "    neighbor = distances_viz[i][1]\n",
        "    plt.plot([query[0], neighbor[0]], [query[1], neighbor[1]], \n",
        "             'g--', alpha=0.5, linewidth=1.5)\n",
        "    \n",
        "    # Add distance annotations\n",
        "    mid_x = (query[0] + neighbor[0]) / 2\n",
        "    mid_y = (query[1] + neighbor[1]) / 2\n",
        "    plt.annotate(f'd={distances_viz[i][0]:.2f}', \n",
        "                xy=(mid_x, mid_y), fontsize=8, \n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
        "\n",
        "plt.xlabel('Feature 1', fontsize=12)\n",
        "plt.ylabel('Feature 2', fontsize=12)\n",
        "plt.title(f'KNN Classification (K=3)\\nQuery Point {query} ‚Üí Predicted Class: {label}', \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ The query point {query} is classified as Class '{label}'\")\n",
        "print(f\"\\nThe 3 nearest neighbors are:\")\n",
        "for i in range(3):\n",
        "    neighbor = distances_viz[i][1]\n",
        "    print(f\"  {i+1}. Point {neighbor[:2]} (Class {neighbor[2]}) - Distance: {distances_viz[i][0]:.2f}\")"
      ],
      "metadata": {
        "id": "viz1_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN Classifier for Breast Cancer dataset"
      ],
      "metadata": {
        "id": "icimlBt1MFBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import the libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CA0ZMjhy_PVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the Breast Cancer Wisconsin dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "display(breast_cancer.data)"
      ],
      "metadata": {
        "id": "CSuMkzSuZoqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title KNN on Breast Cancer data set (N = 5)\n",
        "\n",
        "#@title Load the Breast Cancer Wisconsin dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "\n",
        "#Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(breast_cancer.data, breast_cancer.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a KNN classifier object\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "KNN_BC_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 2: Confusion Matrix for K=5"
      ],
      "metadata": {
        "id": "viz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Malignant', 'Benign'],\n",
        "            yticklabels=['Malignant', 'Benign'])\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title(f'Confusion Matrix - KNN (K=5)\\nAccuracy: {accuracy:.4f}', \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, \n",
        "                          target_names=['Malignant', 'Benign']))"
      ],
      "metadata": {
        "id": "viz2_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finding the optimal N value for K-NN Classifier using cross-validation\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Create a range of K values to test\n",
        "k_values = range(3, 22, 2)\n",
        "\n",
        "# Create an empty list to store the mean cross-validation scores\n",
        "mean_scores = []\n",
        "\n",
        "# Loop over the K values and calculate the mean cross-validation score\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
        "  mean_scores.append(scores.mean())\n",
        "\n",
        "\n",
        "#print the k and accuracy\n",
        "for k, accuracy in zip(k_values, mean_scores):\n",
        "  print(f\"K = {k}, Accuracy = {accuracy}\")\n",
        "\n",
        "\n",
        "# Find the index of the K value with the highest mean accuracy score\n",
        "best_k_index = np.argmax(mean_scores)\n",
        "\n",
        "# Find the best K value based on the index\n",
        "best_k = k_values[best_k_index]\n",
        "\n",
        "# Print the best K value and its corresponding mean accuracy score\n",
        "print(\"Best K value: \", best_k)\n",
        "print(\"Mean accuracy score: \", mean_scores[best_k_index])\n"
      ],
      "metadata": {
        "id": "er5lztkThi26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 3: K Value vs Accuracy (Cross-Validation)"
      ],
      "metadata": {
        "id": "viz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot K vs Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(k_values, mean_scores, marker='o', linewidth=2, markersize=8, color='blue')\n",
        "plt.axvline(x=best_k, color='red', linestyle='--', linewidth=2, \n",
        "           label=f'Best K = {best_k}')\n",
        "plt.axhline(y=mean_scores[best_k_index], color='green', linestyle='--', \n",
        "           linewidth=2, alpha=0.5, label=f'Best Accuracy = {mean_scores[best_k_index]:.4f}')\n",
        "\n",
        "# Highlight the best point\n",
        "plt.scatter(best_k, mean_scores[best_k_index], color='red', s=300, \n",
        "           zorder=5, edgecolors='black', linewidths=2)\n",
        "\n",
        "plt.xlabel('K Value (Number of Neighbors)', fontsize=12)\n",
        "plt.ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "plt.title('K-NN Hyperparameter Tuning: K Value vs Accuracy\\nBreast Cancer Dataset (5-Fold CV)', \n",
        "         fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.xticks(k_values)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìà Accuracy Range: {min(mean_scores):.4f} to {max(mean_scores):.4f}\")\n",
        "print(f\"üìä Accuracy Variation: {max(mean_scores) - min(mean_scores):.4f}\")"
      ],
      "metadata": {
        "id": "viz3_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Which distance metric is giving the best accuracy?\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer Wisconsin dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Store results\n",
        "metric_results = {}\n",
        "\n",
        "# Try different distance metrics\n",
        "for metric in ['euclidean', 'manhattan', 'minkowski']:\n",
        "    # Train the KNN model\n",
        "    knn = KNeighborsClassifier(n_neighbors = 13, metric = metric)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the classes of the test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    metric_results[metric] = accuracy\n",
        "    print(\"Accuracy ({}): {}\".format(metric, accuracy))\n"
      ],
      "metadata": {
        "id": "O5He8qYeVEml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 4: Distance Metric Comparison"
      ],
      "metadata": {
        "id": "viz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plot comparing distance metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "metrics = list(metric_results.keys())\n",
        "accuracies = list(metric_results.values())\n",
        "\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "bars = plt.bar(metrics, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.4f}',\n",
        "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Highlight the best metric\n",
        "best_metric = max(metric_results, key=metric_results.get)\n",
        "best_idx = metrics.index(best_metric)\n",
        "bars[best_idx].set_edgecolor('gold')\n",
        "bars[best_idx].set_linewidth(4)\n",
        "\n",
        "plt.xlabel('Distance Metric', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title(f'Comparison of Distance Metrics (K=13)\\nBest Metric: {best_metric.capitalize()} ({metric_results[best_metric]:.4f})', \n",
        "         fontsize=14, fontweight='bold')\n",
        "plt.ylim(min(accuracies) - 0.01, max(accuracies) + 0.01)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüèÜ Best Distance Metric: {best_metric.upper()}\")\n",
        "print(f\"üìä Accuracy Difference: {max(accuracies) - min(accuracies):.4f}\")"
      ],
      "metadata": {
        "id": "viz4_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 5: Decision Boundary using PCA (2D)"
      ],
      "metadata": {
        "id": "viz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Reduce to 2 dimensions using PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(data.data)\n",
        "\n",
        "# Split the PCA-transformed data\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, data.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train KNN on PCA data\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=13, metric='manhattan')\n",
        "knn_pca.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "# Create mesh for decision boundary\n",
        "h = 0.5  # step size in the mesh\n",
        "x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "# Predict for each point in the mesh\n",
        "Z = knn_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_light)\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=data.target, cmap=cmap_bold,\n",
        "           edgecolor='black', s=50, alpha=0.7)\n",
        "\n",
        "plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
        "plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
        "plt.title('KNN Decision Boundary (K=13, Manhattan Distance)\\nBreast Cancer Dataset - PCA Visualization', \n",
        "         fontsize=14, fontweight='bold')\n",
        "plt.legend(['Malignant', 'Benign'], loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Total variance explained by 2 components: {sum(pca.explained_variance_ratio_):.2%}\")\n",
        "print(f\"‚úÖ Test accuracy on PCA data: {knn_pca.score(X_test_pca, y_test_pca):.4f}\")"
      ],
      "metadata": {
        "id": "viz5_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Lab 10) KNN Classifier for Wine dataset"
      ],
      "metadata": {
        "id": "jLRnMKfdPMjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title KNN Classifier using scikit learn (Wine Dataset)\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Load the wine dataset\n",
        "wine = load_wine()\n",
        "\n",
        "# Define the features and target variable\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Set up K-fold cross-validation with K=10\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize a list to store the accuracy for each value of K\n",
        "accuracy_list = []\n",
        "\n",
        "# Test the KNN classifier for k=3 to k=21 with step size 2 using K-fold cross-validation\n",
        "for k in range(3, 22, 2):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    accuracy_sum = 0\n",
        "    for train_index, test_index in kfold.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        knn.fit(X_train, y_train)\n",
        "        accuracy_sum += knn.score(X_test, y_test)\n",
        "    accuracy = accuracy_sum / 10\n",
        "    accuracy_list.append(accuracy)\n",
        "    print(f\"K = {k}, Accuracy = {accuracy}\")\n",
        "\n",
        "# Find the best value of K based on the highest accuracy\n",
        "best_k = accuracy_list.index(max(accuracy_list)) * 2 + 3\n",
        "print(f\"\\nBest K = {best_k} with accuracy {max(accuracy_list)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hAvaZfHiQ2S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 6: K Value vs Accuracy (Wine Dataset)"
      ],
      "metadata": {
        "id": "viz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = range(3, 22, 2)\n",
        "\n",
        "# Plot K vs Accuracy for Wine dataset\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(k_range, accuracy_list, marker='o', linewidth=2, markersize=8, \n",
        "        color='purple', label='Accuracy')\n",
        "plt.axvline(x=best_k, color='red', linestyle='--', linewidth=2, \n",
        "           label=f'Best K = {best_k}')\n",
        "plt.axhline(y=max(accuracy_list), color='green', linestyle='--', \n",
        "           linewidth=2, alpha=0.5, label=f'Best Accuracy = {max(accuracy_list):.4f}')\n",
        "\n",
        "# Highlight the best point\n",
        "best_idx = accuracy_list.index(max(accuracy_list))\n",
        "plt.scatter(best_k, accuracy_list[best_idx], color='red', s=300, \n",
        "           zorder=5, edgecolors='black', linewidths=2)\n",
        "\n",
        "plt.xlabel('K Value (Number of Neighbors)', fontsize=12)\n",
        "plt.ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "plt.title('K-NN Hyperparameter Tuning: K Value vs Accuracy\\nWine Dataset (10-Fold CV)', \n",
        "         fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.xticks(k_range)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìà Accuracy Range: {min(accuracy_list):.4f} to {max(accuracy_list):.4f}\")\n",
        "print(f\"üìä Accuracy Variation: {max(accuracy_list) - min(accuracy_list):.4f}\")"
      ],
      "metadata": {
        "id": "viz6_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test KNN Wine Classifier with these two samples\n",
        "\n",
        "# Train the KNN classifier on the entire wine dataset using the best value of K\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Create two new wine samples and test your classifier\n",
        "new_samples = np.array([[12.0, 2.35, 2.50, 21.5, 85.0, 1.65, 1.59, 0.42, 1.30, 2.80, 0.90, 2.45, 420.0],\n",
        "                        [13.5, 2.61, 2.48, 20.5, 120.0, 1.75, 0.84, 0.48, 1.56, 2.52, 0.98, 2.85, 1035.0]])\n",
        "\n",
        "# Predict the class labels of the new wine samples\n",
        "new_sample_labels = knn.predict(new_samples)\n",
        "\n",
        "# Print the predicted class labels of the new wine samples\n",
        "print(f\"\\nNew sample 1 has class label {new_sample_labels[0]}\")\n",
        "print(f\"New sample 2 has class label {new_sample_labels[1]}\")"
      ],
      "metadata": {
        "id": "lg_QH6K0m5hF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 7: Wine Dataset - PCA Visualization with Predictions"
      ],
      "metadata": {
        "id": "viz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA for Wine dataset\n",
        "pca_wine = PCA(n_components=2)\n",
        "X_wine_pca = pca_wine.fit_transform(wine.data)\n",
        "\n",
        "# Transform new samples to PCA space\n",
        "new_samples_pca = pca_wine.transform(new_samples)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot existing wine samples\n",
        "colors = ['red', 'blue', 'green']\n",
        "markers = ['o', 's', '^']\n",
        "for i, (color, marker) in enumerate(zip(colors, markers)):\n",
        "    plt.scatter(X_wine_pca[y == i, 0], X_wine_pca[y == i, 1], \n",
        "               c=color, marker=marker, s=80, alpha=0.6, \n",
        "               edgecolors='black', label=f'Class {i}')\n",
        "\n",
        "# Plot new samples\n",
        "for idx, (sample, label) in enumerate(zip(new_samples_pca, new_sample_labels)):\n",
        "    plt.scatter(sample[0], sample[1], c=colors[label], marker='*', \n",
        "               s=500, edgecolors='gold', linewidths=3, \n",
        "               label=f'New Sample {idx+1} ‚Üí Class {label}', zorder=5)\n",
        "    \n",
        "    # Add annotation\n",
        "    plt.annotate(f'Sample {idx+1}\\n(Class {label})', \n",
        "                xy=(sample[0], sample[1]), \n",
        "                xytext=(20, 20), textcoords='offset points',\n",
        "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n",
        "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', lw=2))\n",
        "\n",
        "plt.xlabel(f'First Principal Component ({pca_wine.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
        "plt.ylabel(f'Second Principal Component ({pca_wine.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
        "plt.title(f'Wine Dataset - PCA Visualization with New Sample Predictions\\nKNN Classifier (K={best_k})', \n",
        "         fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='best', fontsize=9)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Total variance explained by 2 components: {sum(pca_wine.explained_variance_ratio_):.2%}\")\n",
        "print(f\"\\nüç∑ Wine Dataset Classes:\")\n",
        "print(f\"  Class 0: {wine.target_names[0]}\")\n",
        "print(f\"  Class 1: {wine.target_names[1]}\")\n",
        "print(f\"  Class 2: {wine.target_names[2]}\")"
      ],
      "metadata": {
        "id": "viz7_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualization 8: Confusion Matrix for Wine Dataset"
      ],
      "metadata": {
        "id": "viz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Split wine data for final evaluation\n",
        "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
        "    wine.data, wine.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train with best K\n",
        "knn_final = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_final.fit(X_train_wine, y_train_wine)\n",
        "y_pred_wine = knn_final.predict(X_test_wine)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_wine = confusion_matrix(y_test_wine, y_pred_wine)\n",
        "accuracy_wine = accuracy_score(y_test_wine, y_pred_wine)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_wine, annot=True, fmt='d', cmap='RdYlGn', cbar=True,\n",
        "            xticklabels=wine.target_names,\n",
        "            yticklabels=wine.target_names)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title(f'Confusion Matrix - Wine Dataset\\nKNN (K={best_k}) - Accuracy: {accuracy_wine:.4f}', \n",
        "         fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_wine, y_pred_wine, \n",
        "                          target_names=wine.target_names))"
      ],
      "metadata": {
        "id": "viz8_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Summary: Key Visualizations Added\n",
        "\n",
        "### ‚úÖ Visualizations Included:\n",
        "\n",
        "1. **Basic KNN Visualization** - 2D scatter plot showing training data, query point, and K nearest neighbors with distance annotations\n",
        "\n",
        "2. **Confusion Matrix (Breast Cancer)** - Heatmap showing model performance with true vs predicted classifications\n",
        "\n",
        "3. **K Value Optimization** - Line plot showing how accuracy changes with different K values (cross-validation)\n",
        "\n",
        "4. **Distance Metric Comparison** - Bar chart comparing Euclidean, Manhattan, and Minkowski distances\n",
        "\n",
        "5. **Decision Boundary (PCA)** - 2D visualization of decision boundaries using Principal Component Analysis\n",
        "\n",
        "6. **Wine Dataset K Optimization** - Similar to #3 but for wine dataset\n",
        "\n",
        "7. **Wine PCA with Predictions** - PCA visualization showing new sample predictions in feature space\n",
        "\n",
        "8. **Wine Confusion Matrix** - Multi-class confusion matrix for wine classification\n",
        "\n",
        "### üéØ Learning Outcomes:\n",
        "- Understanding how K-NN makes decisions based on proximity\n",
        "- Visualizing the impact of hyperparameter tuning (K value)\n",
        "- Comparing different distance metrics\n",
        "- Seeing decision boundaries in reduced dimensions\n",
        "- Evaluating model performance through confusion matrices\n"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
